{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test reading in a single subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 661), ('i', 313), ('a', 302), ('to', 282), ('and', 278)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = \"./word_count/\"\n",
    "yearMonth = \"RC_2009-04_\"\n",
    "subreddit = '\"anime\"'\n",
    "\n",
    "word_dict = {}\n",
    "file = open(dataDir + yearMonth + subreddit +'.txt')\n",
    "for line in file:\n",
    "    value, key = line.split() #count, word\n",
    "\n",
    "    word_dict[key] = int(value)\n",
    "\n",
    "list(word_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all subreddits to dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"./word_count/\"\n",
    "\n",
    "sub_dict = {}\n",
    "for filename in glob.glob(os.path.join(dataDir, '*.txt')):\n",
    "    subreddit = ''.join(re.findall('\"([^\"]*)\"', filename)) #get name of sub\n",
    "    word_dict = {}\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f: \n",
    "        for line in f:\n",
    "            value, key = line.split() #count, word\n",
    "\n",
    "            word_dict[key] = int(value)\n",
    "    sub_dict[subreddit] = word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for s in sub_dict:\n",
    "    if 'the' in sub_dict[s]:\n",
    "        cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(sub_dict)\n",
    "\n",
    "df = defaultdict(int)\n",
    "for s in sub_dict:\n",
    "    for w in sub_dict[s]: #count of subs where w appears\n",
    "        df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sub_dict:\n",
    "    for key, value in sub_dict[s].items():\n",
    "        # Note = rather than +=, different versions of tf could be used instead\n",
    "        tfidf = ((sum(sub_dict[s].values())-value) *\n",
    "                 (math.log2(N / df[key])))\n",
    "        sub_dict[s][key] = tfidf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['have', 'some', 'can', 'more', 'poker'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(sub_dict['poker'].items(), key=lambda item: item[1])\n",
    "     [-5:]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF ['admitted', 'accomplished', 'abusing', 'abortions', '10000']\n",
      "poker ['have', 'some', 'can', 'more', 'poker']\n",
      "craigslist ['just', 'had', 'your', 'guy', 'dont']\n",
      "food ['2', 'less', 'everything', 'delicious', 'chicken']\n",
      "doctorwho ['the', 'and', 'it', 'to', 'is']\n",
      "javascript ['but', 'deleted', 'are', 'not', 'can']\n",
      "politics ['analogous', 'ag', '4chan', '49', '250']\n",
      "reddithax ['people', 'know', 'community', 'sure', 'new']\n",
      "Design ['way', 'time', 'look', 'had', 'could']\n",
      "Survivalist ['people', 'at', 'with', 'they', 'flu']\n",
      "Austin ['this', 'they', 'as', 'but', 'about']\n",
      "Economics ['adjust', 'absence', '99', '90s', '16']\n",
      "Python ['going', 'function', 'does', 'call', 'been']\n",
      "iphone ['have', 'be', 'this', 'iphone', 'but']\n",
      "Israel ['idf', 'her', 'completely', 'attack', 'around']\n",
      "hackers ['it', 'on', 'this', 'was', 'information']\n",
      "starcraft ['on', 'was', 'but', 'he', 'game']\n",
      "Cryptogon ['but', 'are', 'they', 'as', 'or']\n",
      "Christianity ['commit', 'commandments', 'check', 'chance', 'appear']\n",
      "windowshots ['and', 'it', 'that', 'in', 'you']\n",
      "SuicideWatch ['dark', 'common', 'check', 'along', 'act']\n",
      "collapse ['new', 'good', 'now', 'these', 'other']\n",
      "NSFW_nospam ['on', 'but', 'with', 'are', 'she']\n",
      "nonprofit ['in', 'it', 'for', 'not', 'be']\n",
      "linux ['complex', 'canonical', 'besides', 'b', 'admit']\n",
      "Boobies ['is', 'that', 'you', 'deleted', 'her']\n",
      "Sexy ['in', 'for', 'her', 'deleted', 'she']\n",
      "tomorrowiwill ['is', 'for', 'be', 'my', 'im']\n",
      "ruby ['code', 'there', 'by', 'do', 'at']\n",
      "obama ['tell', 'line', 'her', 'health', 'article']\n",
      "australia ['already', 'yeah', 'while', 'problem', 'network']\n",
      "education ['or', 'at', 'they', 'as', 'their']\n",
      "funny ['audio', 'attached', 'anger', 'acceptable', '24']\n",
      "cogsci ['matter', 'hours', 'drugs', 'done', 'ai']\n",
      "joos ['this', 'why', 'with', 'your', 'have']\n",
      "lgbt ['seem', 'religious', 'nothing', 'last', 'having']\n",
      "cannabis ['my', 'its', 'marijuana', 'we', 'more']\n",
      "opensource ['about', 'was', 'will', 'there', 'good']\n",
      "MensRights ['experience', 'except', 'disagree', 'cannot', 'based']\n",
      "Cooking ['kosher', 'eat', 'cooking', 'green', 'any']\n",
      "4chan ['and', 'for', 'this', 'in', 'n']\n",
      "pics ['aww', 'awhile', 'appearance', 'apocalypse', 'african']\n",
      "Green ['dont', 'would', 'so', 'can', 'think']\n",
      "Fitness ['are', 'dont', 'be', 'can', 'as']\n",
      "economy ['understand', 'pretty', 'oh', 'kids', 'fuck']\n",
      "videos ['direct', 'computer', 'certainly', 'boring', 'beginning']\n",
      "web_design ['load', 'host', 'editor', 'clear', 'bandwidth']\n",
      "ja ['deleted']\n",
      "atheism ['affiliation', 'accidents', '5050', '22', '21']\n",
      "ass ['the', 'i', 'deleted']\n",
      "MapleLinks ['was', 'with', 'my', 'be', 'at']\n",
      "gaming ['advertising', '500', '2fort', '14', '1000']\n",
      "de ['einen', 'schon', 'ja', 'haben', 'habe']\n",
      "redditmusicclub ['their', 'two', 'something', 'point', 'next']\n",
      "business ['attention', 'areas', 'amazing', '90', '9']\n",
      "xboxlive ['my', 'be', 'just', 'with', 'if']\n",
      "zombies ['with', 'as', 'zombie', 'be', 'they']\n",
      "pic ['i', 'the']\n",
      "japan ['more', 'have', 'from', 'people', 'about']\n",
      "electronicmusic ['out', 'be', 'music', 'me', 'if']\n",
      "WeAreTheMusicMakers ['electronic', 'definitely', 'cover', 'between', 'artists']\n",
      "MMA ['only', 'any', 'take', 'fighting', 'say']\n",
      "apple ['google', 'game', 'entire', 'disk', 'basically']\n",
      "Metal ['my', 'are', 'have', 'they', 'be']\n",
      "space ['said', 'name', 'money', 'isnt', 'galaxy']\n",
      "PHP ['do', 'amp', 'would', 'as', 'used']\n",
      "sports ['let', 'else', 'already', 'agree', '4']\n",
      "geek ['eyes', 'dude', 'book', 'account', 'access']\n",
      "canada ['blame', 'behind', 'alcohol', 'above', '15']\n",
      "hardware ['with', 'on', 'be', 'have', 'if']\n",
      "math ['nothing', 'having', 'geometry', 'distribution', 'already']\n",
      "Music ['brother', 'boy', 'behind', 'average', 'asking']\n",
      "ZenHabits ['with', 'not', 'on', 'do', 'about']\n",
      "socialism ['place', 'id', 'however', 'deleted', 'am']\n",
      "hockey ['well', 'really', 'hes', 'yeah', 'even']\n",
      "compsci ['if', 'have', 'data', 'use', 'more']\n",
      "redditchan ['the']\n",
      "lisp ['its', 'women', 'more', 'than', 'all']\n",
      "history ['cavalry', 'well', 'used', 'much', 'could']\n",
      "tonightsdinner ['little', 'do', 'at', 'pepper', 'garlic']\n",
      "india ['for', 'be', 'have', 'with', 'are']\n",
      "howto ['get', 'from', 'or', 'me', 'dont']\n",
      "Amateur ['a']\n",
      "humor ['two', 'theyre', 'show', 'own', 'every']\n",
      "energy ['say', 'far', 'cars', 'carbon', 'actually']\n",
      "gundem ['bir']\n",
      "Anarchism ['jesus', 'hope', 'fuck', 'found', 'alternative']\n",
      "Frugal ['long', 'hour', 'her', 'give', 'card']\n",
      "gardening ['or', 'with', 'they', 'not', 'your']\n",
      "Buddhism ['its', 'your', 'they', 'one', 'about']\n",
      "PS3 ['at', 'will', 'there', 'or', 'ive']\n",
      "worldpolitics ['between', 'until', 'matter', 'else', 'change']\n",
      "offbeat ['cash', 'beat', 'basic', 'apply', 'according']\n",
      "religion ['ever', 'change', 'big', 'around', 'always']\n",
      "grist ['and', 'it', 'to', 'that', 'deleted']\n",
      "Marijuana ['careful', 'arrested', 'apparently', 'ah', '9']\n",
      "Pictures ['in', 'you', 'this', 'was', 'with']\n",
      "gonewild ['pics', 'much', 'ill', 'has', 'say']\n",
      "gossip ['on', 'health', 'term', 'with', 'online']\n",
      "LegalTeens ['the', 'that', 'is', 'it', 'deleted']\n",
      "Art ['see', 'people', 'way', 'them', 'reddit']\n",
      "it ['dei', 'nel', 'gli', 'anche', 'sono']\n",
      "Drugs ['little', 'ill', 'else', 'effect', 'getting']\n",
      "unitedkingdom ['government', 'were', 'how', 'any', 'well']\n",
      "government ['people', 'was', 'government', 'about', 'states']\n",
      "firefox ['is', 'that', 'in', 'you', 'for']\n",
      "aprilfool2009 ['this', 'in', 'you', 'for', 'was']\n",
      "latinoamerica ['de', 'deleted', 'en', 'y']\n",
      "women ['whole', 'while', 'talking', 'course', 'anything']\n",
      "Physics ['can', 'speed', 'by', 'about', 'like']\n",
      "bicycling ['first', 'different', 'buy', 'anything', 'never']\n",
      "collaborative_hub ['what', 'something', 'one', 'just', 'has']\n",
      "motorcycles ['riding', 'an', 'this', 'im', 'or']\n",
      "nsfw ['him', 'hell', 'hand', 'arent', 'again']\n",
      "writing ['day', 'yourself', 'words', 'these', 'am']\n",
      "environment ['bags', 'among', 'agriculture', 'age', 'afford']\n",
      "Freethought ['world', 'word', 'too', 'may', 'into']\n",
      "bestof ['next', 'making', 'bad', 'another', 'agree']\n",
      "photography ['through', 'start', 'shutter', 'getting', 'd90']\n",
      "AskReddit ['afghanistan', 'admitting', 'accordingly', '999', '247']\n",
      "guns ['easy', 'completely', 'comment', 'city', '2nd']\n",
      "lost ['do', 'up', 'from', 'dont', 'at']\n",
      "software ['for', 'in', 'have', 'on', 'with']\n",
      "Bad_Cop_No_Donut ['he', 'on', 'cops', 'like', 'just']\n",
      "UFOs ['its', 'with', 'at', 'what', 'an']\n",
      "soccer ['is', 'a', 'and', 'the', 'to']\n",
      "psychology ['though', 'school', 'need', 'ive', 'am']\n",
      "DIY ['as', 'so', 'just', 'they', 'one']\n",
      "vegan ['dont', 'deleted', 'think', 'just', 'as']\n",
      "moviecritic ['not', 'film', 'my', 'one', 'about']\n",
      "Health ['population', 'lifestyle', 'large', 'happy', 'fucking']\n",
      "reddit.com ['accusing', 'acceleration', '510', '2ch', '1997']\n",
      "ireland ['are', 'be', 'on', 'this', 'have']\n",
      "conspiracies ['not', 'on', 'are', 'they', 'he']\n",
      "architecture ['it', 'you', 'for', 'this', 'be']\n",
      "entertainment ['canadian', 'boys', 'bill', 'aids', '2009']\n",
      "GameDeals ['on', 'have', 'at', 'was', 'game']\n",
      "beer ['as', 'good', 'beers', 'some', 'what']\n",
      "todayilearned ['read', 'probably', 'new', 'am', 'always']\n",
      "Ubuntu ['much', 'time', 'package', 'keyboard', 'jaunty']\n",
      "feminisms ['use', 'thing', 'question', 'culture', 'back']\n",
      "Eve ['are', 'not', 'up', 'eve', 'get']\n",
      "comics ['business', 'basically', 'band', 'artists', '5']\n",
      "philosophy ['class', 'changes', 'capable', 'cancer', 'appear']\n",
      "ads ['your', 'be', 'at', 'so', 'like']\n",
      "science ['agriculture', 'activities', 'achieve', 'absence', '2007']\n",
      "WebGames ['by', 'because', 'where', 'off', 'much']\n",
      "sex ['hear', 'cultures', 'called', 'call', '5']\n",
      "drunk ['i', 'and', 'you', 'on', 'my']\n",
      "ideasfortheadmins ['some', 'why', 'up', 'me', 'know']\n",
      "ukpolitics ['always', 'these', 'say', 'quite', 'against']\n",
      "movies ['short', 'opinion', 'half', 'far', 'damn']\n",
      "Bacon ['when', 'too', 'should', 'think', 'ive']\n",
      "Pets ['dog', 'be', 'my', 'if', 'but']\n",
      "cpp ['not', 'c', 'just', 'be', 'int']\n",
      "mexico ['los', 'no', 'es', 'por', 'se']\n",
      "911truth ['scientific', 'peer', 'path', 'journal', 'come']\n",
      "wikipedia ['case', 'system', 'society', 'japanese', 'heard']\n",
      "lists ['was', 'you', 'with', 'are', 'not']\n",
      "law ['im', 'any', 'court', 'who', 'really']\n",
      "haskell ['space', 'other', 'even', 'step', 'will']\n",
      "technology ['architecture', 'appeal', 'aol', '80s', '4gb']\n",
      "3cs ['deleted']\n",
      "self ['freedom', 'felt', 'doubt', 'definitely', 'clutch']\n",
      "Pandemic ['trying', 'panic', 'likely', 'isnt', 'death']\n",
      "worldnews ['ambassador', 'accusations', 'abortion', '46', '28']\n",
      "Poetry ['by', 'or', 'about', 'some', 'its']\n",
      "xkcd ['at', 'up', 'by', 'from', 'about']\n",
      "programming ['acknowledge', 'accuracy', '810', '2gb', '17']\n",
      "netsec ['since', 'pretty', 'off', 'did', 'always']\n",
      "Documentaries ['for', 'this', 'you', 'on', 'was']\n",
      "aww ['if', 'cat', 'would', 'they', 'more']\n",
      "Guitar ['one', 'good', 'so', 'just', 'play']\n",
      "ronpaul ['has', 'one', 'its', 'dont', 'out']\n",
      "conspiracy ['energy', 'based', 'apparently', 'almost', '1']\n",
      "video ['what', 'deleted', 'as', 'people', 'or']\n",
      "es ['deleted']\n",
      "lolcats ['it', 'in', 'this', 'my', 'cat']\n",
      "Military ['also', 'then', 'had', 'other', 'been']\n",
      "happy ['find', 'those', 'makes', 'down', 'anything']\n",
      "meetup ['are', 'we', 'not', 'out', 'have']\n",
      "scifi ['line', 'hours', 'explanation', 'amp', '8']\n",
      "HappyBirthday ['we', 'from', 'well', 'up', 'at']\n",
      "rpg ['his', 'give', 'being', 'back', '3']\n",
      "skeptic ['much', 'work', 'thats', 'said', 'isnt']\n",
      "news ['become', 'ban', 'allow', 'actual', '5']\n",
      "Libertarian ['equal', 'caused', 'begin', 'articles', '4']\n",
      "gadgets ['couple', 'comment', 'card', 'bought', 'anyway']\n",
      "TheistVsAtheist ['other', 'will', 'only', 'being', 'how']\n",
      "books ['reason', 'ones', 'idea', 'god', 'completely']\n",
      "islam ['his', 'him', 'at', 'just', 'created']\n",
      "travel ['can', 'will', 'so', 'some', 'as']\n",
      "anime ['very', 'some', 'see', 'cyberpunk', 'were']\n",
      "Equality ['brain', 'beyond', 'assault', 'ass', 'abused']\n"
     ]
    }
   ],
   "source": [
    "for s in sub_dict:\n",
    "    print(s, \n",
    "          list(dict(sorted(sub_dict[s].items(), \n",
    "                      key=lambda item: item[1])[-5:]).keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
