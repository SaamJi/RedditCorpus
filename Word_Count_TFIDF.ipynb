{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must have n lines\n",
    "# read in contents of single file as dictionary\n",
    "# load all files as idct of dicts\n",
    "# calculate tf-idf for each word\n",
    "# get top n \n",
    "\n",
    "#sparse matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in files to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: CrowdfundedBoardgames\n",
      "Time elapsed: 96.46595406532288 seconds\n",
      "Total Time elapsed: 96.46697521209717 seconds\n",
      "We have 11427 Subreddits\n",
      "Found problems with 122 subreddits\n"
     ]
    }
   ],
   "source": [
    "src_dir = '/Users/choldawa/Documents/Projects/RedditCorpus/word_count/RC_2012-12'\n",
    "\n",
    "tick = time.time()\n",
    "\n",
    "d = {}\n",
    "problem_subs = []\n",
    "cnt = 0\n",
    "for file in os.listdir(src_dir):\n",
    "    path = src_dir+\"/\"+file\n",
    "    with open(path) as f:\n",
    "        filename = os.path.basename(file).split(\"_\")[2].split(\".\")[0]\n",
    "        clear_output(wait=True)\n",
    "        print(f\"working on: {filename}\")\n",
    "        tock = time.time()\n",
    "        print(f\"Time elapsed: {tock - tick} seconds\")\n",
    "        sub_d = {}\n",
    "        num_lines = sum(1 for line in open(path)) #must have at least 100 unique words\n",
    "        if num_lines > 100:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    (val, key) = line.strip().split() #invert the order \n",
    "                    if not any(map(str.isdigit, key)) and int(val)>1: # each word must occur more than once\n",
    "                         if key not in stop_words: #check if stopword   \n",
    "                            sub_d[key] = int(val)\n",
    "                except:\n",
    "                    problem_subs.append(filename)\n",
    "            d[filename] = sub_d\n",
    "end = time.time()\n",
    "print(f\"Total Time elapsed: {end - tick} seconds\")\n",
    "print(f\"We have {len(d)} Subreddits\")\n",
    "print(f\"Found problems with {len(problem_subs)} subreddits\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some example first and last items:\n",
      "Common words:\n",
      "[('people', 116175), ('would', 84858), ('dont', 77698), ('like', 70930), ('one', 56556)]\n",
      "Uncommon words:\n",
      "[('abccbsnbc', 2), ('abbreviations', 2), ('abbrasive', 2), ('abbottabad', 2), ('abbotsford', 2), ('abbos', 2), ('abbiex', 2), ('abbasled', 2), ('abating', 2), ('abated', 2), ('aardvarks', 2), ('aah', 2), ('aaguns', 2), ('aaah', 2), ('aaaah', 2), ('aaaaannndd', 2), ('aaaaaaaaaand', 2), ('aaaaaaaaaaand', 2), ('aaaaaaaaaaaand', 2), ('รก', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are some example first and last items:\")\n",
    "print(\"Common words:\")\n",
    "print(list(d['politics'].items())[:5])\n",
    "print(\"Uncommon words:\")\n",
    "print(list(d['politics'].items())[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(d)\n",
    "\n",
    "df = defaultdict(int)\n",
    "for s in d:\n",
    "    for w in d[s]: #count of subs where w appears\n",
    "        df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['crypto']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN tf-idf approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "dv = DictVectorizer()\n",
    "#D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}] #EXAMPLE FORMAT\n",
    "X = dv.fit_transform(list(d.values()))\n",
    "tv = TfidfTransformer()\n",
    "tfidf = tv.fit_transform(X)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11427, 652887)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "# Define the type of our output array elements: (int, float)\n",
    "dt = np.dtype([('index', np.int32, 1), ('value', np.float64, 1)])\n",
    "\n",
    "# Take the indices of the largest k elements from each row\n",
    "top_k_inds = np.argsort(tfidf.toarray())[:, -1:-k - 1:-1]\n",
    "\n",
    "# Take the values at those indices\n",
    "top_k = np.take_along_axis(tfidf.toarray(), top_k_inds, axis=-1)\n",
    "\n",
    "# Stack the two together along a third axis (to get index-value pairs)\n",
    "top_k_pairs = np.stack((top_k_inds, top_k), axis=2)\n",
    "\n",
    "# Convert the type (otherwise we have the indices as floats)\n",
    "# top_k_pairs = top_k_pairs.astype(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.98118000e+05, 3.93636720e-01],\n",
       "       [6.47480000e+04, 1.93462826e-01],\n",
       "       [1.26528000e+05, 1.83498888e-01],\n",
       "       [4.18186000e+05, 1.57209444e-01],\n",
       "       [3.89239000e+05, 1.43874628e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teamfight\n",
      "void\n",
      "earlygame\n",
      "ult\n",
      "sven\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top_k_pairs[22])):\n",
    "    print(dv.get_feature_names()[int(top_k_pairs[22][i][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6172"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.keys()).index('wallstreetbets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit: r/wallstreetbets\n",
      "\n",
      "top content by count:\n",
      "['think', 'im', 'get', 'approval', 'heb', 'time', 'short', 'adcom', 'good', 'dont']\n",
      "\n",
      "top tfidf for r/wallstreetbets:\n",
      "adcom\n",
      "heb\n",
      "approval\n",
      "pdufa\n",
      "ampligen\n"
     ]
    }
   ],
   "source": [
    "subreddit = 'wallstreetbets' #wallstreetbets #crypto #nba #Conservative\n",
    "index = list(d.keys()).index(subreddit)\n",
    "print(f'Subreddit: r/{subreddit}')\n",
    "print()\n",
    "print('top content by count:')\n",
    "print(list(d[list(d.keys())[index]])[:10])\n",
    "print()\n",
    "print(f'top tfidf for r/{subreddit}:')\n",
    "for i in range(len(top_k_pairs[index])):\n",
    "    print(dv.get_feature_names()[int(top_k_pairs[index][i][0])])\n",
    "#dv.get_feature_names()[int(top_k_pairs[index][0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['the']/len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(d.keys()) # rowNames\n",
    "#list(d.values()) #dictionary input to tfidf\n",
    "# dv.get_feature_names() #colNames\n",
    "# list(set(key for dic in D for key in dic.keys())) #colNames\n",
    "\n",
    "#get topN\n",
    "#feature_array = np.array(tfidf.get_feature_names())\n",
    "# tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "# n = 3\n",
    "# top_n = feature_array[tfidf_sorting][:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Calculations (our way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict = copy.deepcopy(d) #make a deepcopy (need to copy nested obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(sub_dict)\n",
    "\n",
    "df = defaultdict(int)\n",
    "for s in sub_dict:\n",
    "    for w in sub_dict[s]: #count of subs where w appears\n",
    "        df[w] += 1\n",
    "print(f\" We have {N} sub_reddits and {df['game']} contain 'game'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sub_dict:\n",
    "    for key, value in sub_dict[s].items():\n",
    "        tf = (value/\n",
    "                  ((sum(sub_dict[s].values())-value)+1))\n",
    "        idf = (np.log(N / df[key]))\n",
    "        tfidf = tf*idf\n",
    "        sub_dict[s][key] = tfidf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in sub_dict:\n",
    "    print(s, \n",
    "          list(dict(sorted(sub_dict[s].items(), \n",
    "                           key=lambda item: item[1], reverse = True)\n",
    "                    [:3]).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('12_2012_tfidf.pickle', 'wb') as handle:\n",
    "    pickle.dump(sub_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12_2012_tfidf.pickle', 'rb') as handle:\n",
    "    sub_dict = pickle.load(handle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histogram of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {len(df)} unique words and {len(d)} unique subreddits\")\n",
    "logD = {k:np.log10(v) for k, v in df.items()}\n",
    "plt.hist(logD.values(), bins = 25)\n",
    "plt.xlabel(\"Log10 num of subreddits\")\n",
    "plt.ylabel(\"Count of words\")\n",
    "plt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with Counter (not sure if it works with non-integers...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_reddit = 'america' #america #politics # theoffice\n",
    "# topN = 10\n",
    "# c = Counter(sub_dict[sub_reddit]) #create counter\n",
    "\n",
    "# most_common = c.most_common(topN) # get topN tf-idf\n",
    "# most_common\n",
    "\n",
    "# plt.bar(range(len(most_common)), [val[1] for val in most_common], align='center')\n",
    "# plt.xticks(range(len(most_common)), [val[0] for val in most_common])\n",
    "# plt.xticks(rotation=70)\n",
    "# plt.title(sub_reddit)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting sorted dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_reddit = 'theoffice' # theoffice\n",
    "topN = 6\n",
    "x = list(dict(sorted(sub_dict[sub_reddit].items(), \n",
    "                           key=lambda item: item[1], reverse = True)\n",
    "                    [:topN]).keys())\n",
    "y = list(dict(sorted(sub_dict[sub_reddit].items(), \n",
    "                           key=lambda item: item[1], reverse = True)\n",
    "                    [:topN]).values())\n",
    "\n",
    "\n",
    "plt.bar(x,y, align='center')\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(sub_reddit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [{\"sub_1\":{'foo': 1, \"bar\":2}}, \n",
    "     {\"sub_2\": {'foo':3, \"baz\": 10, 'bar':2}}]\n",
    "\n",
    "#take a list of dictionaries with dictionaries\n",
    "#run sklearn tf-idf to get matrix\n",
    "# access top N tf-df for any row \n",
    "# get the names of those words (with highest tf-idf)\n",
    "# tie that row back to the name of the subreddit\n",
    "\n",
    "d[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
